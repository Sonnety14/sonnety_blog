---
title: "线性代数学习笔记"
description: "一点思考"
date: 2025-12-17T00:00:00+08:00
image: mat_head.png
math: true
license: 
hidden: false
comments: true
draft: false
categories:
    - math
tags:
    - 数学
    - 线性代数
---

### 秩的次可加性

$$r(A+B) \le r(A) + r(B)$$

$r(A)$ 代表 $A$ 的列向量张成的空间（列空间）的维数。

$A+B$ 的列向量，是由 $A$ 的列向量和 $B$ 的列向量相加得到的。

直觉： 两个空间拼起来，新空间的维数肯定不会超过原来两个空间维数的总和。

### Sylvester 秩不等式

$$r(AB) \ge r(A) + r(B) - n$$

我不会证。

### 矩阵对角化与换基的联系

对于一个向量 **$\alpha$**，其在基 **$A$** 下的表现形式为 **$A^{-1}\alpha$**。

那么将基变换至基 **$B$** 下，其变为 **$(B^{-1}A) \cdot A^{-1}\alpha \Rightarrow B^{-1}\alpha$**。

辅助矩阵为 **$P$**， **$P = B^{-1}A$**， **$B\cdot P=A$**。

据上，(基 **$A$** 下的) 线性变换 **$C$** 至 (基 **$B$** 下的) 线性变换 **$D$**：


$$
\begin{aligned}
v_{a}&=C\cdot u_{a}\\
P\cdot v_{b}&=C\cdot (P\cdot u_{b})\\
P^{-1}\cdot P\cdot v_{b}&=P^{-1}\cdot C\cdot P\cdot u_{b}\\
D &= P^{-1} C P
\end{aligned}
$$

可见，变换 **$C$** 与变换 **$D$** 在物理意义上相同，只是坐标系不同的表现形式。

那么，对于矩阵对角化 **$A = P^{-1}\Lambda P$**。

**$\Lambda$** 是特征值的对角矩阵，其基为特征向量组成的基 $P$，**$P$** 是列向量为特征向量的矩阵。

$A$ 的基是标准基 $E$。

(基 **$E$** 下的) 线性变换 **$A$** 至 (基 **$P$** 下的) 线性变换 **$\Lambda$**：

辅助矩阵为 **$D = P^{-1}E$**。

$$
\begin{aligned}
\Lambda &= D^{-1}AD\\
A &= D\Lambda D^{-1} = P^{-1}\Lambda P
\end{aligned}
$$

### 矩阵对角化与齐次线性方程组（几何重数）

* 代数重数 (Algebraic Multiplicity) 定义：
  * 当 $(\lambda E - A)\alpha = 0$，其中 $\alpha$ 是特征向量不为 $0$ 向量时， $\lambda E - A$ 一定不满秩，其行列式为 $0$。
  * 特征多项式 $|\lambda E - A| = 0$ 算出来后，这个 $\lambda$ 是几重根。
  * 通俗理解：名义上的数量。比如算出来 $(\lambda - 2)^3 = 0$，那 $\lambda=2$ 的代数重数就是 3。
  
* 几何重数 (Geometric Multiplicity)定义：
  * 齐次方程组 $(A - \lambda E)x = 0$ 的基础解系里所含向量的个数。也就是线性无关的特征向量的个数。
  * 用公式算就是： $n - r(A - \lambda E)$  （未知数个数 - 矩阵的秩）。

那么对于任何一个特征值，存在：

$$1 \le \text{几何重数} \le \text{代数重数}$$

即，只要是特征值，至少有一个特征向量（几何重数 $\ge 1$ ）。
但是实际找到的独立特征向量个数，绝不可能超过它作为根出现的次数（几何重数 $\le$ 代数重数）。

当一个矩阵想要对角化，那么它的辅助矩阵 $P$ 就要填满 $n$ 个线性无关的特征向量，也就是其 **几何重数必须等于 $n$**。

举个简单的例子。

矩阵 $A$（可对角化）：

$$
A = 
\begin{pmatrix} 
2 & 0 \\
0 & 2 
\end{pmatrix}
$$

特征值： $\lambda=2,2$ 。代数重数 $= 2$。

求特征向量：解 $(A-2E)x=0$，即 

$$
\begin{pmatrix}
0 & 0 \\
0 & 0 
\end{pmatrix}x=0
$$

几何重数：秩是 $0$，自由变量有 $2-0=2$ 个。

几何重数 $= 2$。结论： $2=2$ ，可以对角化（它自己已经是了）。

矩阵 B（不可对角化）：

$$
B = 
\begin{pmatrix}
2 & 1 \\ 
0 & 2 
\end{pmatrix}
$$

特征值： $\lambda = 2, 2$ 。代数重数 $= 2$ 。

求特征向量：解 $(B-2E)x=0$ ，即

$$
\begin{pmatrix}
0 & 1 \\
0 & 0 
\end{pmatrix}x=0
$$

几何重数：秩是 $1$ ，自由变量有 $2-1=1$ 个。

几何重数 $= 1$ 。结论： $1 < 2$ ，不可以对角化。

#### 实对称矩阵一定可以对角化

简单来说，实对称矩阵之所以“一定”能对角化，甚至能“完美”对角化（正交对角化），是由它的对称性（ $A^T = A$ ）这种完美的结构决定的。

数学上通常用 Schur 分解 来证明这一点：

* 任何方阵都可以被分解为 $A = QUQ^T$，其中 $U$ 是上三角矩阵。
* 因为 $A$ 是对称的 ($A=A^T$)，所以 $QUQ^T = (QUQ^T)^T = QU^TQ^T$。
* 这就强迫 $U = U^T$。一个既是上三角、又是对称的矩阵，只能是对角矩阵！
* 所以 $A$ 直接就等于 $Q \Lambda Q^T$，直接对角化了。

#### 正交对角化

普通对角化是找一个可逆矩阵 $P$，使得：

$$P^{-1} A P = \Lambda$$ 。

正交对角化则是找一个正交矩阵 $Q$ （通常用 $Q$ 或 $P$ 表示），使得：

$$Q^{-1} A Q = Q^T A Q = \Lambda$$

这里的关键区别在于矩阵 $Q$：它必须是一个正交矩阵。

这意味着：公式更简单：正交矩阵的逆矩阵等于转置矩阵（ $Q^{-1} = Q^T$ ）。

结构更完美：$Q$ 的列向量（特征向量）必须两两垂直（正交）且长度为 $1$（单位化）。

再也不用辛苦求逆了，把行变列就行。

在几何意义上讲，

* 普通对角化 ($P$)：找到的新坐标系（特征向量）可能是歪斜的。虽然在这个歪斜的坐标系里计算变简单了，但坐标轴之间的夹角可能不是 90 度，空间被“挤压”了。
* 正交对角化 ($Q$)：找到的新坐标系是完美的直角坐标系。这意味着，我们只是把原来的坐标轴做了一个刚性的旋转，没有改变空间的形状，也没有改变夹角。

而

**一个实矩阵 $A$ 可以被正交对角化，当且仅当 $A$ 是对称矩阵（ $A = A^T$ ）。**

### 谱分解 or 特征分解。

如果说“对角化”是把矩阵“拉直”了看，那么“谱分解”就是把矩阵 **“拆碎”** 了看。

针对实对称矩阵 $A$ ：

$$A = P \Lambda P^T$$

（因为实对称矩阵可以正交对角化，所以 $P^{-1} = P^T$ ）

我们把这个矩阵乘法暴力展开：

$$
A=\underbrace{
\begin{pmatrix}
p_1 & p_2 & \dots & p_n 
\end{pmatrix}}_{P} 
\underbrace{
\begin{pmatrix}
\lambda_1 & & & \\
& \lambda_2 & & \\
& & \ddots & \\
& & & \lambda_n 
\end{pmatrix}}
_{\Lambda}
\underbrace{
\begin{pmatrix}
p_1^T \\
p_2^T \\
\vdots \\
p_n^T 
\end{pmatrix}}
_{P^T}
$$

这个连乘式可以写成一个求和式：

$$A = \lambda_1 \underbrace{p_1 p_1^T}_{P_1} + \lambda_2 \underbrace{p_2 p_2^T}_{P_2} + \dots + \lambda_n \underbrace{p_n p_n^T}_{P_n}$$

这就是谱分解公式： 

$$A = \sum_{i=1}^n \lambda_i p_i p_i^T$$ 

公式里有两部分核心元素：

1. $\lambda_i$ ：这是特征值，代表在第 $i$ 个方向上的拉伸倍数。
2. $p_i p_i^T$：方向，这是一个 $n \times n$ 的矩阵，我们通常记为 $P_i$（大写 $P$ ）。这个矩阵有一个响亮的名字：正交投影矩阵。

它的物理意义是：把任何一个向量，强制 **投影** 到 $p_i$ 所指的那条直线上。

这些投影矩阵 $P_i$ 有非常完美的性质：
* 对称性： $P_i^T = P_i$。
* 幂等性： $P_i^2 = P_i$ （投影两次等于投影一次，因为第一次投影完已经在直线上，再投也不改变）。
* 互斥性： $P_i P_j = O$ （当 $i \neq j$ 时）。因为不同特征向量互相垂直，投影到 $x$ 轴后再投影到 $y$ 轴，结果就是 0。
* 完备性： $P_1 + P_2 + \dots + P_n = E$ （把所有方向的投影加起来，就是原原本本的世界）。

举个简单的例子：
假设

$$
A = 
\begin{pmatrix}
3 & 0 \\
0 & 1 
\end{pmatrix}
$$ 

* $\lambda_1 = 3$ ，特征向量

$$
p_1 =
\begin{pmatrix}
1 \\
0
\end{pmatrix}
$$


* $\lambda_2 = 1$，特征向量

$$
p_2 =
\begin{pmatrix}
0 \\
1
\end{pmatrix}
$$

做谱分解：


$$
\begin{aligned}
A &= 3 \cdot 
\begin{pmatrix} 
1 \\
0 
\end{pmatrix}
\begin{pmatrix} 
1 & 0 
\end{pmatrix} + 1 \cdot 
\begin{pmatrix} 
0 \\
1 
\end{pmatrix} 
\begin{pmatrix} 
0 & 1 
\end{pmatrix} \\
&= 3 \cdot 
\begin{pmatrix} 
1 & 0 \\
0 & 0 
\end{pmatrix} + 1 \cdot 
\begin{pmatrix} 
0 & 0 \\
0 & 1 
\end{pmatrix} \\
&= \begin{pmatrix}
3 & 0 \\
0 & 0 
\end{pmatrix} + 
\begin{pmatrix}
0 & 0 \\
0 & 1 
\end{pmatrix} \\
&= 
\begin{pmatrix} 
3 & 0 \\
0 & 1 
\end{pmatrix}
\end{aligned}
$$

它把矩阵拆成了“只作用于 x 轴的部分”和“只作用于 y 轴的部分”。

#### 例题

三阶实对称方阵 $A$ 的特征值为 $6,3,3$ ，若对应于 $6$ 的特征向量 $p_1=(1,1,1)^{T}$ ，求方阵 $A$。

对于实对称矩阵，如果特征值为 $\lambda_1$ 和 $\lambda_2$ （重根），且 $\lambda_1$ 对应的特征向量为 $p_1$ ，那么矩阵 $A$ 可以表示为：

$$A = \lambda_1 P_1 + \lambda_2 (E - P_1)$$

其中：
* $P_1$ 是向 $p_1$ 方向投影的矩阵：$P_1 = \frac{p_1 p_1^T}{p_1^T p_1}$ 。
* $E$ 是单位矩阵。
* $E - P_1$ 其实就是投影到与 $p_1$ 垂直的空间（即 $\lambda=3$ 的特征空间）的投影矩阵。

具体计算：

1. 整理已知条件特征值：

* $\lambda_1 = 6$（单根），$\lambda_2 = \lambda_3 = 3$ （二重根）。

* 特征向量：$p_1 = (1, 1, 1)^T$。

2. 化简公式代入公式：

$$A = 6 P_1 + 3 (E - P_1)$$

展开合并同类项：

$$A = 6 P_1 + 3E - 3 P_1$$

$$\mathbf{A = 3E + 3 P_1}$$

(这一步大大简化了计算，我们只需要算 $P_1$ 即可)

3. 计算投影矩阵 $P_1$


$$
p_1 p_1^T = 
\begin{pmatrix} 
1 \\
1 \\
1 
\end{pmatrix} 
\begin{pmatrix} 
1 & 1 & 1 
\end{pmatrix} =
\begin{pmatrix} 
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1 
\end{pmatrix}
$$


$$p_1^T p_1 = 1^2 + 1^2 + 1^2 = 3$$

所以：

$$
P_1 = \frac{1}{3} 
\begin{pmatrix} 
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1 
\end{pmatrix}
$$

4. 代入求最终结果

$$
A = 3 
\begin{pmatrix} 
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 
\end{pmatrix}
+3 
\cdot
\frac{1}{3}
\begin{pmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{pmatrix}
$$

$$
A = 
\begin{pmatrix} 
3& 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 3 
\end{pmatrix} 
+
\begin{pmatrix} 
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1 
\end{pmatrix}
$$

$$
A = 
\begin{pmatrix} 
4 & 1 & 1 \\ 
1 & 4 & 1 \\
1 & 1 & 4 
\end{pmatrix}
$$

### 相似矩阵与换基的关系

[ref:维基百科](https://zh.wikipedia.org/wiki/%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%99%A3)

把 **线性变换** 想象成一个物理动作，比如把一个气球捏扁、或者旋转一个魔方。

$$B = P^{-1} A P$$

* **线性变换 ( $T$ )**：是那个“捏”或“转”的**动作本身**（它是客观存在的，不依赖于你用什么尺子去量它）。
* **矩阵 ( $A$ 和 $B$ )**：是你为了描述这个动作，不同系下记录的矩阵。
  * 在“标准坐标系”下描述，写出来的矩阵是 **$A$**。
  * 在“特征坐标系”下描述，写出来的矩阵是 **$B$**。

因为线性变换是同一个，所以这个线性变换的 **本质属性** 是绝对不会变的。

即 **特征值、行列式、秩** 一定相同。

#### 特征值相同：
特征值代表的是**“伸缩倍数”**。

如果这个变换是“把某根棍子拉长 2 倍”（ $\lambda = 2$ ）。

* 不管你是用“米”做单位（基 $A$），还是用“英尺”做单位（基 $B$），这根棍子被拉长 **2 倍** 这个物理事实是不会变的。
* 尺子的刻度（基）变了，但这根棍子的长度变化比率（特征值）不可能变。

这里的 “棍子” 指的就是特征向量的方向。

**代数证明:**

相似意味着存在 $P$ 使得 $B = P^{-1} A P$。
我们看它们的**特征多项式** $|\lambda E - B|$：

$$\begin{aligned}
|\lambda E - B| &= |\lambda E - P^{-1} A P| \\
&= |P^{-1} (\lambda E) P - P^{-1} A P| \quad (\text{因为 } \lambda E \text{ 是对角阵，可交换}) \\
&= |P^{-1} (\lambda E - A) P| \\
&= |P^{-1}| \cdot |\lambda E - A| \cdot |P| \\
&= |P|^{-1} \cdot |P| \cdot |\lambda E - A| \\
&= |\lambda E - A|
\end{aligned}$$

**结论：** 既然特征多项式一模一样，解出来的根（特征值）自然也一模一样。

---

#### 行列式相同：

**几何直觉：**
行列式代表的是**“体积的放大率”**。
如果一个变换把一个单位立方体的体积放大了 $5$ 倍（ $|A|=5$ ）。

* 不管你建立什么坐标系去测量，这个物体体积膨胀的倍数（ $5$ 倍）是客观事实。
* 坐标系的变化不会改变物体体积膨胀的本质。

**代数证明（严谨）：**
利用行列式的乘法性质 $|XY| = |X||Y|$：

$$\begin{aligned}
|B| &= |P^{-1} A P| \\
&= |P^{-1}| \cdot |A| \cdot |P| \\
&= \frac{1}{|P|} \cdot |A| \cdot |P| \\
&= |A|
\end{aligned}$$

**结论：** $|B| = |A|$ 。

#### 特征向量不同：

虽然**特征值**相同，但 **特征向量** 在不同基下的坐标是 **不同** 的。

* **物理上**：那个“不转弯的方向”在空间中是固定的。
* **坐标上**：
  * 在旧基下，这个方向的坐标是 $x$。
  * 在新基下，这个方向的坐标变成了 $P^{-1}x$。
##
